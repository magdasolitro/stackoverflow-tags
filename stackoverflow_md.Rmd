---
title: "StackOverflow Tags Network"
author: "Magdalena Solitro"
date: '2022-07-14'
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
    css: 'scrollable.css'
editor_options:
  chunck_output_type: console
---

```{r setup, echo=FALSE, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r preliminaries, echo=FALSE, include=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(tidygraph)
library(ggraph)
library(ggplot2)
library(readr)
library(igraph)
library(corrplot)
library(lpSolve)
library(lpSolveAPI)
library(knitr)
library(kableExtra)

setwd("/Users/magda/Desktop/ADS/stackoverflow-tags/")

```


```{r function_def}
# functions definition
similarity = function(g, type = "cosine", mode = "col" ) {
	A = as_adjacency_matrix(g, attr = "weight", sparse = FALSE)
	if (mode == "row") {A = t(A)}
	if (type == "cosine") {
		euclidean = function(x) {sqrt(x %*% x)}
		d = apply(A, 2, euclidean)
		D = diag(1/d)
		S = D %*% t(A) %*% A %*% D
	}
	if (type == "pearson") {
		S = cor(A)
	}
	return(S)
}

shannon = function(p) {
	x = p * log2(p)
	x = replace(x, is.nan(x), 0)
	return(-sum(x))
}

simpson = function(p) {
	x = 1 - sum(p * p)
	return(x)
}

rao = function(p, D) {
	x = diag(p) %*% D %*% diag(p)
	return(sum(c(x)))
}


heterogeneity = function(g, D, mode = "col") {
	A = as_adjacency_matrix(g, attr = "weight", sparse = FALSE)
	if (mode == "col") {
		A = A %*% diag(1/colSums(A))
		dim = 2
	} else {
		A = diag(1/rowSums(A)) %*% A
		dim = 1
	}
	return(list(shannon = apply(A, dim, shannon),
				simpson = apply(A, dim, simpson),
				rao = apply(A, dim, rao, D)))
}

regularify = function (g) {
  n = vcount(g)
  m = ecount(g)
  E = get.edges(g, E(g))
  B = matrix(0, nrow = n, ncol = m)
  # build incidence matrix
  for (i in 1:m) {
    B[E[i,1], i] = 1
    B[E[i,2], i] = 1
  }  
  # objective function
  obj = rep(0, m + 1)
  # constraint matrix
  con = cbind(B, rep(-1, n))
  # direction of constraints
  dir = rep("=", n)
  # right hand side terms
  rhs = -degree(g)
  # solve the LP problem
  sol = lp("max", obj, con, dir, rhs)
  # get solution
  if (sol$status == 0) {
    s = sol$solution
    # weights
    w = s[1:m] + 1
    # weighted degree
    d = s[m+1]
  }
  # return the solution
  if (sol$status == 0) {
    return(list(weights = w, degree = d)) 
  }
  else {
    return(NULL)   
  }
}

power = function(A, t) {
  n = dim(A)[1];
  # x_2k
  x0 = rep(0, n);
  # x_2k+1
  x1 = rep(1, n);
  # x_2k+2
  x2 = rep(1, n);
  diff = 1
  eps = 1/10^t;
  iter = 0;
  while (diff > eps) {
    x0 = x1;
    x1 = x2;
    x2 = (1/x2) %*% A;
    diff = sum(abs(x2 - x0));
    iter = iter + 1;
  } 
  # it holds now: alpha x2 = (1/x2) A
  alpha = ((1/x2) %*% A[,1]) / x2[1];
  # hence sqrt(alpha) * x2 = (1/(sqrt(alpha) * x2)) A
  x2 = sqrt(alpha) %*% x2;
  return(list(vector = as.vector(x2), iter = iter))
} 

```

```{r graph, echo=FALSE, include=FALSE, warning=FALSE, message=FALSE}
# load dataset graph
edges_path = "dataset/stack_network_links.csv"
nodes_path = "dataset/stack_network_nodes.csv"

edges = read_csv(edges_path)
nodes = read_csv(nodes_path)[-2]

# generate graph
graph = tbl_graph(nodes = nodes, edges = edges, directed = TRUE)

```

## A network of tags used in StackOverflow
The network we analyse represents the usage of tags on StackOverflow, a popular forum for computer programmers. Tags are keywords that help users to find questions and answers related to a specific technology or topic. 

Our dataset is structured in two files:

- *stack_network_nodes.csv* is a csv file containing information about the nodes of the network. Each node is associated to a specific tag.

- *stack_network_links.csv* is a csv file containing information about the links of the network. An edge between two nodes means that the those tags can be found in the same post. The weight of the edge is a measure of how often those tags are used together. 

The goal of my analysis is to deduce information about the technologies represented by tags based on how they relate to each other in the network. More precisely, we would like to see if it is possible to ...

## Centrality
Centrality measures are a way of determining the "importance" of a node in the network based on how it connects to its neighbours.

## Centrality measures
I used three different centrality measures: degree centrality, betweenness centrality, and Katz centrality.

```{r centrality, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}

<<<<<<< HEAD
# weighted degree
=======
# degree
>>>>>>> 2b297abe08918d8e5f299da1ec5b0dfa3d6253de
str = strength(graph, v = V(graph), mode = "all", loops = FALSE)

# betweenness
betweenness = betweenness(graph)

# katz centrality
A = as_adjacency_matrix(graph)
eig = eigen(A)$values
r = max(abs(eig))
alpha = 0.85 / r
katz = alpha_centrality(graph, alpha = alpha, exo = 1)

# plot graph
ggraph(graph, layout = 'kk') +
	geom_edge_link(aes(edge_alpha = value)) +
<<<<<<< HEAD
	geom_node_point(aes(size = str, colour = betweenness)) +
=======
	geom_node_point(aes(size = katz, colour = betweenness)) +
>>>>>>> 2b297abe08918d8e5f299da1ec5b0dfa3d6253de
	geom_node_label(aes(label = nodes$name), label.size = 0.25, repel = TRUE) +
	theme_void()
```

## Comparison with the expected flow
An alternative way of evaluating how meaningful is a link between two nodes is two compare flow of the network with the flow that can be found in a network with the same nodes, where the links are distributed randomly.

```{r exp_flow, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}
n_nodes = vcount(graph)

F = matrix(scan("dataset/flows.txt", what = numeric(0), sep=","),
		   nrow = n_nodes, ncol = n_nodes)

tag = scan("dataset/tags_names.txt", what = character(0), sep="\n")

out_flow = rowSums(F)
names(out_flow) = tag

in_flow = colSums(F)
names(in_flow) = tag

flows = tibble(tag = tag, in_flow = in_flow, out_flow = out_flow) %>%
	mutate(id = row_number()) %>%
	select(id, everything())

# normalize by expected flows 
R = diag(rowSums(F))
C = diag(colSums(F))
n = sum(diag(C))
O = matrix(1, nrow = n_nodes, ncol = n_nodes)

# expected flow
E = (R %*% O %*% C) / n
# normalized flows (X-test)
C = (F - E) / sqrt(E) 

g = graph_from_adjacency_matrix(C, mode = "plus", weighted = TRUE)
V(g)$name = 1:vcount(g)

chi = as_tibble(as_data_frame(g)) %>%
	left_join(flows, by = c("from" = "id")) %>%
	left_join(flows, by = c("to" = "id")) %>%
	select(from, to, weight, tag.x, tag.y)

# top 5 different discipline pairs
top = filter(chi, from != to) %>%
	arrange(desc(weight)) %>%
	head(5)

# bottom 5 different discipline pairs
btm = filter(chi, from != to) %>% 
  arrange(weight) %>%
  head(5)

top %>%
    kbl(align="c", caption='Top 5 Entries') %>%
    kable_material(c("striped", "hover", "condensed"), font_size = 20)

btm %>%
    kbl(align="c", caption='Bottom 5 Entries') %>%
    kable_material(c("striped", "hover", "condensed"), font_size = 20)

```

## Community detection
We can ask ourselves: is it possible to identify tags that refer to similar technologies through community detection? 

We try to answer this question using **community detection**, a technique that helps us to identify groups of tags that are more strongly connected to each other.

```{r communities, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}
# COMMUNITY DETECTION
groups = cluster_walktrap(graph)
mod = modularity(groups)

# add group column to nodes tibble
nodes = nodes %>% add_column(group = as.integer(membership(groups)))

community = as.factor(membership(groups))

ggraph(graph, layout = 'fr') +
	geom_edge_link() +
	geom_node_point(aes(size = 1, colour = community)) +
	geom_node_label(aes(label = nodes$name), label.size = 0.25, repel = TRUE) +
	scale_color_brewer(palette = "Paired")
```

The nodes assigned to Group 3 correspond to technologies that are commonly used for **Machine Learning applications**.

```{r groups, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}

options(knitr.table.format = "html")

group3 <-
	nodes %>%
	group_by(group) %>%
    as.data.frame() %>%
    filter(group==3) %>%
    select(name, group)

group7 <-
	nodes %>%
	group_by(group) %>%
    as.data.frame() %>%
    filter(group==7) %>%
    select(name, group)

group8 <-
	nodes %>%
	group_by(group) %>%
    as.data.frame() %>%
    filter(group==8) %>%
    select(name, group)

group3 %>%
    kbl(align="c") %>%
    kable_material(c("striped", "hover", "condensed"), font_size = 20)

```

## Group 7 and 8
Group 7 is instead composed by only two members, Angular2 and TypeScript: turns out that the former is a languaged based on latter!

```{r group7, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}
group7 %>%
  kbl(align="c") %>%
  kable_material(c("striped", "hover", "condensed"), font_size = 15)
```

The last example is Group 8, which comprehends technologies are used for the development of Apple products: **Objective-C** has been for a long time the primary programming language for writing software for **OS X** and **iOS**, while more recently **Swift** was introduced as an improvement of Objective-C.

```{r group8, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}
group8 %>%
  kbl(align="c") %>%
  kable_material(c("striped", "hover", "condensed"), font_size = 15)
```

## Size of communities
We can plot communities with a histogram to compare the size of each group.

```{r histogram, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}

# group together nodes that belong to the same group and count elements
group_sizes <-
	nodes %>%
	group_by(group) %>%
	count()

# plot histogram
ggplot(group_sizes, aes(x=group, y=n)) + 
	geom_col(data=group_sizes, aes(x=group, y=n))
```

## Hierarchical Clustering
A more advanced way of grouping together tags based on their domain is **Hierarchical Clustering**, which establishes a hierarchy of nodes based on the similarity score between them.

For example:

- 50 is Ubuntu and 56 is Unix
- 8 is C and 9 is C++

```{r hierachical_clust, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}
# use hierarchical clustering to group tags into macroareas

# hierarchical clustering
A = as_adjacency_matrix(graph, sparse=FALSE)

# cosine similarity
euclidean = function(x) {sqrt(x %*% x)}
d = apply(A, 2, euclidean)
D = diag(1/d)
S = D %*% t(A) %*% A %*% D

# distance matrix
D = 1-S

# distance object
dist = as.dist(D)

# average-linkage clustering method
hc = hclust(dist, method = "average")

plot(hc)
```

## Similarity and Heterogeneity
```{r, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}
f = graph_from_adjacency_matrix(F, mode = "directed", weighted = TRUE)
V(f)$name = 1:vcount(f)

S = similarity(f)
D = 1 - S
het = heterogeneity(f, D)

flows = mutate(flows, shannon_id = het$shannon, simpson_id = het$simpson, rao_id = het$rao)

flows_id = select(flows, contains("_id"))
corrplot.mixed(cor(flows_id), upper = "ellipse")
```

## Interdisciplinarity (or versatility)
The five most interdisciplinary tags are
```{r}
x <- arrange(flows, desc(rao_id)) %>% 
    select(tag, contains("_id")) %>%
    head(5)

x %>%
  kbl(align="c") %>%
  kable_material(c("striped", "hover", "condensed"), font_size = 15)
```

## Power measures
We use power to...
```{r power, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}
regularify(graph)
I = diag(0.15, n_nodes)
(AI = A + I)

power(AI, 6)
```